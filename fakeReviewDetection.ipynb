{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./datasets/fake_review_data/fake_reviews_dataset.csv\")\n",
    "data2 = pd.read_csv(\"./datasets/Amazon_Reviews_full-product/amazon_reviews.txt\",delimiter=\"\\t\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                                text  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID       LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0       1  __label1__       4                 N               PC  B00008NG7N   \n",
       "1       2  __label1__       4                 Y         Wireless  B00LH0Y3NM   \n",
       "2       3  __label1__       3                 N             Baby  B000I5UZ1Q   \n",
       "3       4  __label1__       4                 N  Office Products  B003822IRA   \n",
       "4       5  __label1__       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                       PRODUCT_TITLE  \\\n",
       "0        Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "1  Note 3 Battery : Stalion Strength Replacement ...   \n",
       "2       Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "3  Casio MS-80B Standard Function Desktop Calculator   \n",
       "4  Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "               REVIEW_TITLE                                        REVIEW_TEXT  \n",
       "0                    useful  When least you think so, this product will sav...  \n",
       "1     New era for batteries  Lithium batteries are something new introduced...  \n",
       "2  doesn't swing very well.  I purchased this swing for my baby. She is 6 m...  \n",
       "3          Great computing!  I was looking for an inexpensive desk calcolat...  \n",
       "4     Only use twice a week  I only use it twice a week and the results are...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[data1[\"label\"] == \"CG\", \"label\"] = 1\n",
    "data1.loc[data1[\"label\"] == \"OR\", \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.loc[data2[\"LABEL\"] == \"__label1__\", \"LABEL\"] = 1\n",
    "data2.loc[data2[\"LABEL\"] == \"__label2__\", \"LABEL\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Module,Dropout,Linear,Embedding,LayerNorm,BatchNorm1d\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryReviewDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        review = row[\"text\"] + \"[EOS]\"\n",
    "        label = row[\"label\"]\n",
    "        category = \" \".join(row[\"category\"].split(\"_\")[:-1])\n",
    "        rating = row[\"rating\"]\n",
    "        \n",
    "        reviewEncoding = self.tokenizer(review, return_tensors=\"pt\")\n",
    "        reviewEncoding['category'] = self.tokenizer(category, return_tensors=\"pt\")['input_ids']\n",
    "        reviewEncoding['rating'] = torch.tensor(rating, dtype=torch.float32)\n",
    "        reviewEncoding[\"label\"] = torch.tensor(label)\n",
    "        return reviewEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    text, categories, ratings, labels = [], [], [], []\n",
    "    for sample in batch:\n",
    "        text.append(sample['input_ids'].squeeze(0))\n",
    "        categories.append(sample['category'].squeeze(0))\n",
    "        ratings.append(sample['rating'])\n",
    "        labels.append(sample[\"label\"])\n",
    "    text = pad_sequence(text,batch_first=True,padding_value=0)\n",
    "    categories = pad_sequence(categories,batch_first=True,padding_value=0)\n",
    "    return text, categories, torch.stack(ratings), torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodings(Module):\n",
    "    def __init__(self, d_model:int, max_len:int=512):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        pe = torch.zeros((max_len, d_model))\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        return (self.pe[:x.size(1), :]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class FakeReviewIdentifier(Module):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 d_model:int,\n",
    "                 num_classes:int,\n",
    "                 vocab_size:int,\n",
    "                 dropout_rate:float):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.positionalEncoding = PositionalEncodings(d_model)\n",
    "\n",
    "        self.model = model\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.layerNorm = LayerNorm(d_model)\n",
    "\n",
    "        self.fc1 = Linear(d_model,d_model//2)\n",
    "        self.fc2 = Linear(d_model//2,num_classes)\n",
    "\n",
    "        self.fcNum1 = Linear(1,d_model//2)\n",
    "        self.fcNum2 = Linear(d_model//2,d_model)\n",
    "\n",
    "    def forward(self, text, category, rating, attnMask):\n",
    "        x = self.embedding(text) + self.positionalEncoding(text)\n",
    "        xCategory = self.embedding(category) + self.positionalEncoding(category)\n",
    "\n",
    "        xOut = self.model(x,xCategory,attnMask)\n",
    "\n",
    "        xRatOut = self.fcNum1(rating)\n",
    "        xRatOut = self.fcNum2(xRatOut)\n",
    "\n",
    "        xRatOut = xRatOut.unsqueeze(1)\n",
    "        x = torch.cat([xOut,xRatOut],dim=1)\n",
    "        _,x = torch.max(x,dim=1)\n",
    "        x = x.to(torch.float32)\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data1.sample(frac=0.8)\n",
    "val_data = data1.drop(train_data.index)\n",
    "test_data = val_data.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "train_loader = DataLoader(CategoryReviewDataset(train_data, tokenizer), batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(CategoryReviewDataset(val_data, tokenizer), batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(CategoryReviewDataset(test_data, tokenizer), batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryAttention(Module):\n",
    "    def __init__(self,\n",
    "                 d_model:int=512,\n",
    "                 n_heads:int=8):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_head\"\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model//n_heads\n",
    "\n",
    "        self.Wk = Linear(d_model,d_model)\n",
    "        self.Wq = Linear(d_model,d_model)\n",
    "        self.Wv = Linear(d_model,d_model)\n",
    "        self.Wo = Linear(d_model,d_model)\n",
    "\n",
    "    def forward(self,query,key,value,mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        Q = self.Wq(query)\n",
    "        K = self.Wk(key)\n",
    "        V = self.Wv(value)\n",
    "\n",
    "        Q = Q.view(batch_size,-1,self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        K = K.view(batch_size,-1,self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "        V = V.view(batch_size,-1,self.n_heads,self.head_dim).permute(0,2,1,3)\n",
    "\n",
    "        energy = torch.matmul(Q,K.permute(0,1,3,2)) / torch.sqrt(torch.tensor(self.head_dim,dtype=torch.float32))\n",
    "        if mask is not None:\n",
    "            energy.masked_fill_(mask==0,float(\"-1e20\"))\n",
    "\n",
    "        attnWeights = torch.softmax(energy,dim=1)\n",
    "        out = torch.matmul(attnWeights,V)\n",
    "        out = out.permute(0,2,1,3).contiguous().view(batch_size,-1,self.d_model)\n",
    "\n",
    "        out = self.Wo(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderLayer(Module):\n",
    "    def __init__(self,\n",
    "                 d_model:int=512,\n",
    "                 n_heads:int=8,\n",
    "                 dim_feedforward:int=2048,\n",
    "                 dropout:float=0.1,\n",
    "                 activation:Any = F.relu_):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cat_attn = CategoryAttention(d_model,n_heads)\n",
    "        \n",
    "        self.fc1 = Linear(d_model,dim_feedforward)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "        self.fc2 = Linear(dim_feedforward,d_model)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "        \n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self,\n",
    "                sent1:Tensor,\n",
    "                sent2:Tensor,\n",
    "                attnMask:Tensor=None):\n",
    "        \n",
    "        attnOut = self.cat_attn(sent1,sent2,sent2,attnMask)\n",
    "        resConn = sent1 + self.dropout1(attnOut)\n",
    "        normOut = self.norm1(resConn)\n",
    "\n",
    "        FFNOutp = self.activation(self.fc1(normOut))\n",
    "        FFNProd = self.fc2(self.dropout(FFNOutp))\n",
    "\n",
    "        out = resConn + self.dropout2(FFNProd)\n",
    "        out = self.norm2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ModuleList\n",
    "\n",
    "class TransformerEncoder(Module):\n",
    "    def __init__(self,\n",
    "                 encoder_layer:Module,\n",
    "                 num_layers:int=8,\n",
    "                 d_model:int=512,\n",
    "                 n_heads:int=8,\n",
    "                 dim_feedforward:int=2048,\n",
    "                 dropout:float=0.1,\n",
    "                 activation:Any=F.relu_):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = ModuleList([encoder_layer(d_model,n_heads,dim_feedforward,dropout,activation) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self,\n",
    "                sent1:Tensor,\n",
    "                sent2:Tensor,\n",
    "                mask:Any=None):\n",
    "        out = sent1\n",
    "        for layer in self.layers:\n",
    "            out = layer(out,sent2,mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "d_model = 256\n",
    "n_heads = 32\n",
    "num_layers = 32\n",
    "num_classes = 2\n",
    "vocab_size = len(tokenizer)\n",
    "dropout_rate = 0.2\n",
    "dim_feedforward = 1024\n",
    "activation = F.relu\n",
    "\n",
    "baseModel = TransformerEncoder(\n",
    "    TransformerEncoderLayer,\n",
    "    num_layers,\n",
    "    d_model,\n",
    "    n_heads,\n",
    "    dim_feedforward,\n",
    "    dropout_rate,\n",
    "    activation\n",
    ")\n",
    "\n",
    "model = FakeReviewIdentifier(baseModel,d_model,num_classes,vocab_size,dropout_rate)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=2e-3)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(loader, model, loss_fn, optimizer, is_train:bool=False):\n",
    "    model.train(is_train)\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for text, category, rating, labels in loader:\n",
    "        text = text.to(DEVICE)\n",
    "        category = category.to(DEVICE)\n",
    "        \n",
    "        rating = rating.view(-1,1).to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            out = model(text, category, rating, attnMask=None)\n",
    "            loss = loss_fn(out, labels)\n",
    "            _,preds = torch.max(out,dim=1)\n",
    "            acc = (preds==labels).sum().item()/labels.size(0)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "    return total_loss / len(loader), acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.14 GB, other allocations: 704.00 KB, max allowed: 18.13 GB). Tried to allocate 125.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [139]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m bad_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m currEpoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     train_loss,train_acc \u001b[38;5;241m=\u001b[39m epoch(train_loader, model, loss_fn, optimizer, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     val_loss,val_acc \u001b[38;5;241m=\u001b[39m epoch(val_loader, model, loss_fn, optimizer, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 18.14 GB, other allocations: 704.00 KB, max allowed: 18.13 GB). Tried to allocate 125.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_losses, val_losses = [], []\n",
    "patience = 10\n",
    "min_val_loss = 1e9\n",
    "bad_epochs = 0\n",
    "\n",
    "for currEpoch in range(num_epochs):\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    train_loss,train_acc = epoch(train_loader, model, loss_fn, optimizer, is_train=True)\n",
    "    val_loss,val_acc = epoch(val_loader, model, loss_fn, optimizer, is_train=False)\n",
    "\n",
    "    print(f\"Epoch {currEpoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f} | Val Loss: {val_loss:.4f} Val Accuracy{val_acc:.4f}\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "    if bad_epochs == patience:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
